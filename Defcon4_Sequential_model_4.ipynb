{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ae8974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12/20/2021-1\n",
    "# https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n",
    "from __future__ import absolute_import\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from os.path import exists, join\n",
    "\n",
    "\n",
    "\n",
    "contentPath = os.getcwd()\n",
    "cv2Path=join(contentPath, 'CV2Images')\n",
    "testPath=join(contentPath, 'images')\n",
    "checkpointPath = join(contentPath, 'CheckPoints')\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4896a413",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='loss', min_delta=0, patience=1, verbose=1,\n",
    "    mode='auto', baseline=None, restore_best_weights=False,\n",
    "    # print('\\n',\n",
    ")\n",
    "\n",
    "checkpoints = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = checkpointPath,\n",
    "    monitor='loss', verbose=1, save_best_only=True,\n",
    "    save_weights_only=False, mode='auto', save_freq='epoch',\n",
    "    options=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16fe007",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE=(224, 224)\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "train_ds = image_dataset_from_directory(\n",
    "    cv2Path,\n",
    "    color_mode='rgb',\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=456,\n",
    "    image_size=(224, 224),\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE)\n",
    "print()\n",
    "\n",
    "validation_ds = image_dataset_from_directory(\n",
    "    cv2Path,\n",
    "    color_mode='rgb',\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=456,\n",
    "    image_size=(224, 224),\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE)\n",
    "print()\n",
    "\n",
    "test_ds = image_dataset_from_directory(\n",
    "    testPath,\n",
    "    color_mode='rgb',\n",
    "    image_size=(224, 224),\n",
    "    batch_size = BATCH_SIZE)\n",
    "# clear_output()\n",
    "# modelLabels = train_ds.take(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90be910c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_STEPS = 173 // BATCH_SIZE\n",
    "print('TRAIN_STEPS:', TRAIN_STEPS)\n",
    "VAL_STEPS =  43 // BATCH_SIZE\n",
    "print('VAL_STEPS:', VAL_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755b88f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad665df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "img = load_img('data/train/cats/cat.0.jpg')  # this is a PIL image\n",
    "x = img_to_array(img)  # this is a Numpy array with shape (3, 224, 224)\n",
    "x = x.reshape((1,) + x.shape)  \n",
    "# this is a Numpy array with shape (1, 3, 224, 224)\n",
    "# .flow() command generates batches of randomly transform images\n",
    "# and saves the results to the `preview/` directory\n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1,\n",
    "                          save_to_dir='preview', save_prefix='cat', save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 20:\n",
    "        break  # otherwise the generator would loop indefinitely\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44b44e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(3, 224, 224)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# the model so far outputs 3D feature maps (height, width, features)\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "Let's prepare our data. We will use .flow_from_directory() to generate batches of image data (and their labels) directly from our jpgs in their respective folders.\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'data/train',  # this is the target directory\n",
    "        target_size=(224, 224),  # images will be resized to 224x224\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'data/validation',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "We can now use these generators to train our model. Each epoch takes 20-30s on GPU and 300-400s on CPU. So it's definitely viable to run this model on CPU if you aren't in a hurry.\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000 // batch_size,\n",
    "        epochs=50,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=800 // batch_size)\n",
    "model.save_weights('first_try.h5')  # always save your weights after training or during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73338f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69961174",
   "metadata": {},
   "outputs": [],
   "source": [
    "oldShit='''\n",
    "model.fit(\n",
    "    x=train_ds,\n",
    "    y=None,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=5,\n",
    "    verbose='auto',\n",
    "    callbacks=[earlyStop, checkpoints],\n",
    "    validation_split=0.0,\n",
    "    validation_data=validation_ds,\n",
    "    shuffle=True,\n",
    "    class_weight=None,\n",
    "    sample_weight=None,\n",
    "    initial_epoch=0,\n",
    "    steps_per_epoch=TRAIN_STEPS,\n",
    "    validation_steps=VAL_STEPS,\n",
    "    validation_batch_size=BATCH_SIZE,\n",
    "    validation_freq=1,\n",
    "    max_queue_size=2,\n",
    "    workers=1,\n",
    "    use_multiprocessing=True,\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f92fb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = model.name + '.h5'\n",
    "modelSavePath = join(contentPath, modelName)\n",
    "model.save(modelSavePath, overwrite=True)\n",
    "\n",
    "%ls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
