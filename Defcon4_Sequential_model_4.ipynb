{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ae8974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12/20/2021-1\n",
    "# https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n",
    "from __future__ import absolute_import\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import glob, os, shutil\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "from os.path import *\n",
    "from time import sleep\n",
    "from BashColors import C\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "from os.path import exists, join\n",
    "\n",
    "contentPath = os.getcwd()\n",
    "cv2Path=join(contentPath, 'CV2Images')\n",
    "testPath=join(contentPath, 'images')\n",
    "checkpointPath = join(contentPath, 'CheckPoints')\n",
    "\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c707eb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "savePath = join(contentPath, 'preview')\n",
    "if exists(savePath):\n",
    "    print(f'removing: {C.BIRed}{savePath}')\n",
    "    shutil.rmtree(savePath)\n",
    "    sleep(0.1)\n",
    "else: print('gone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4896a413",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='loss', min_delta=0, patience=1, verbose=1,\n",
    "    mode='auto', baseline=None, restore_best_weights=False,\n",
    "    # print('\\n',\n",
    ")\n",
    "\n",
    "checkpoints = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = checkpointPath,\n",
    "    monitor='loss', verbose=1, save_best_only=True,\n",
    "    save_weights_only=False, mode='auto', save_freq='epoch',\n",
    "    options=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874ee89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    # rescale=1./255,\n",
    "    # rotation_range=50,\n",
    "    # width_shift_range=0.1,\n",
    "    # height_shift_range=0.1,\n",
    "    # shear_range=0.1,\n",
    "    # zoom_range=-0.5,\n",
    "    # horizontal_flip=True,\n",
    "    # vertical_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "savePath = join(contentPath, 'preview')\n",
    "if not exists(savePath):\n",
    "    os.makedirs(savePath)\n",
    "friendlyPath= join(cv2Path, 'Friendly')\n",
    "os.chdir(friendlyPath)\n",
    "globList=[]\n",
    "globList = glob.glob('**', recursive=True)\n",
    "print(len(globList))\n",
    "                     \n",
    "for pth in sorted(globList):\n",
    "    fullPath = abspath(pth)\n",
    "    # print(fullPath)\n",
    "    filePath = fullPath\n",
    "    fileName = basename(fullPath)\n",
    "    fileSplit = split(basename(fullPath))\n",
    "    fileSplit = splitext(fileSplit[1])\n",
    "    baseFileName =fileSplit[0]\n",
    "    fileExtension = fileSplit[1]\n",
    "    print(fileName, baseFileName, fileExtension)\n",
    "\n",
    "    img = load_img(fileName)  # this is a PIL image\n",
    "    x = img_to_array(img)  # numpy array with shape (3, 224, 224)\n",
    "    x = x.reshape((1,) + x.shape)\n",
    "    print(x.shape)\n",
    "    # this is a Numpy array with shape (1, 3, 224, 224)\n",
    "    # .flow() command generates batches of randomly transform images\n",
    "    # and saves the results to the `preview/` directory\n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size=1,\n",
    "                              save_to_dir=savePath,\n",
    "                              save_prefix=baseFileName,\n",
    "                              save_format='png'):\n",
    "        i += 1\n",
    "        sleep(0.25)\n",
    "        if i > 1:\n",
    "            break  # otherwise the generator would loop indefinitely\n",
    "clear_output()\n",
    "\n",
    "savePath = join(contentPath, 'preview')\n",
    "os.chdir(savePath)\n",
    "globList=[]\n",
    "globList = glob.glob('**', recursive=True)\n",
    "print(len(globList), 'friendly files')\n",
    "\n",
    "os.chdir(contentPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755b88f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=50,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    rescale=1./255,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=-0.5,\n",
    "    # horizontal_flip=True,\n",
    "    # vertical_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "savePath = join(contentPath, 'preview')\n",
    "if not exists(savePath):\n",
    "    os.makedirs(savePath)\n",
    "enemyPath= join(cv2Path, 'Enemy')\n",
    "os.chdir(enemyPath)\n",
    "globList=[]\n",
    "globList = glob.glob('**', recursive=True)\n",
    "print(len(globList))\n",
    "                     \n",
    "for pth in sorted(globList):\n",
    "    fullPath = abspath(pth)\n",
    "    # print(fullPath)\n",
    "    filePath = fullPath\n",
    "    fileName = basename(fullPath)\n",
    "    fileSplit = split(basename(fullPath))\n",
    "    fileSplit = splitext(fileSplit[1])\n",
    "    baseFileName =fileSplit[0]\n",
    "    fileExtension = fileSplit[1]\n",
    "    print(fileName, baseFileName, fileExtension)\n",
    "\n",
    "    img = load_img(fileName)  # this is a PIL image\n",
    "    x = img_to_array(img)  # numpy array with shape (3, 224, 224)\n",
    "    x = x.reshape((1,) + x.shape)\n",
    "    print(x.shape)\n",
    "    # this is a Numpy array with shape (1, 3, 224, 224)\n",
    "    # .flow() command generates batches of randomly transform images\n",
    "    # and saves the results to the `preview/` directory\n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size=1,\n",
    "                              save_to_dir=savePath,\n",
    "                              save_prefix=baseFileName,\n",
    "                              save_format='png'):\n",
    "        i += 1\n",
    "        sleep(0.25)\n",
    "        if i > 7:\n",
    "            break  # otherwise the generator would loop indefinitely\n",
    "clear_output()\n",
    "\n",
    "savePath = join(contentPath, 'preview')\n",
    "os.chdir(savePath)\n",
    "globList=[]\n",
    "globList = glob.glob('**', recursive=True)\n",
    "print(len(globList), 'enemy files')\n",
    "\n",
    "os.chdir(contentPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfba2bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from CV2_Utils import *\n",
    "savePath = join(contentPath, 'preview')\n",
    "os.chdir(savePath)\n",
    "globList=[]\n",
    "globList = glob.glob('**', recursive=True)\n",
    "print(len(globList), 'enemy files')\n",
    "\n",
    "for pth in sorted(globList):\n",
    "    fullPath = abspath(pth)\n",
    "    if fullPath.__contains__('friendly'):\n",
    "        img = cv2.imread(fullPath, cv2.IMREAD_COLOR)\n",
    "        cvu.plotShowSingleImage(img, title1=basename(fullPath))\n",
    "        sleep(0.1)\n",
    "        img=None\n",
    "        # print(fullPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2e9564",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11ea0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835b6467",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE=(224, 224)\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "TRAIN_STEPS = 173 // BATCH_SIZE\n",
    "print('TRAIN_STEPS:', TRAIN_STEPS)\n",
    "VAL_STEPS =  43 // BATCH_SIZE\n",
    "print('VAL_STEPS:', VAL_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddaad68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling3D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "model = Sequential(name='Defcon4_Sequential_V4')\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(3, 224, 224)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# the model so far outputs 3D feature maps (height, width, features)\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44b44e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'data/train',  # this is the target directory\n",
    "        target_size=(224, 224),  # images will be resized to 224x224\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'data/validation',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000 // batch_size,\n",
    "        epochs=50,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=800 // batch_size)\n",
    "model.save_weights('first_try.h5')  # always save your weights after training or during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73338f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69961174",
   "metadata": {},
   "outputs": [],
   "source": [
    "oldShit='''\n",
    "model.fit(\n",
    "    x=train_ds,\n",
    "    y=None,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=5,\n",
    "    verbose='auto',\n",
    "    callbacks=[earlyStop, checkpoints],\n",
    "    validation_split=0.0,\n",
    "    validation_data=validation_ds,\n",
    "    shuffle=True,\n",
    "    class_weight=None,\n",
    "    sample_weight=None,\n",
    "    initial_epoch=0,\n",
    "    steps_per_epoch=TRAIN_STEPS,\n",
    "    validation_steps=VAL_STEPS,\n",
    "    validation_batch_size=BATCH_SIZE,\n",
    "    validation_freq=1,\n",
    "    max_queue_size=2,\n",
    "    workers=1,\n",
    "    use_multiprocessing=True,\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f92fb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = model.name + '.h5'\n",
    "modelSavePath = join(contentPath, modelName)\n",
    "model.save(modelSavePath, overwrite=True)\n",
    "\n",
    "%ls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
